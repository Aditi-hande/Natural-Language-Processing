{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7fe68f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7fe68f3",
    "outputId": "686a4731-0469-49d7-f4a1-da393e3f3cc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi\\AppData\\Local\\Temp\\ipykernel_14308\\828054624.py:9: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis([\"index\", \"word\", \"tag\"], axis=\"columns\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import operator\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_table('data/train', header=None)#,sep='\\t',lineterminator='\\n')\n",
    "df.set_axis([\"index\", \"word\", \"tag\"], axis=\"columns\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kr_s5HFXQ2op",
   "metadata": {
    "id": "kr_s5HFXQ2op"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba022a9",
   "metadata": {
    "id": "fba022a9"
   },
   "outputs": [],
   "source": [
    "word_counts = {}\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    if row[1] in word_counts:\n",
    "        word_counts[row[1]] += 1\n",
    "    else:\n",
    "        word_counts[row[1]] = 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ed6d15",
   "metadata": {
    "id": "44ed6d15"
   },
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "unkcount = 0\n",
    "unkwords = []\n",
    "\n",
    "for entry in word_counts:\n",
    "    if word_counts[entry] <= threshold:\n",
    "        unkwords.append(entry)\n",
    "        unkcount = unkcount + word_counts[entry]\n",
    "        \n",
    "# replace words with less freq as <unk>\n",
    "\n",
    "df.loc[df['word'] .isin(unkwords),'word'] = '<unk>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c10124",
   "metadata": {
    "id": "24c10124"
   },
   "outputs": [],
   "source": [
    "word_counts = dict( sorted(word_counts.items(), key=operator.itemgetter(1),reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5008c213",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5008c213",
    "outputId": "0930ff9c-a92b-4549-df2c-9bb8bec346b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 13751\n",
      "total occurrences of the special token ‘< unk >’: 42044\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "with open(\"vocab.txt\", 'w') as f:\n",
    "    f.write('<unk>' + '\\\\t' + str(i) + '\\\\t' + str(unkcount) + '\\n')\n",
    "    i +=1\n",
    "    for entry in word_counts:\n",
    "        if word_counts[entry] > threshold:\n",
    "            f.write(entry + '\\\\t' + str(i) + '\\\\t' + str(word_counts[entry]) + '\\n')\n",
    "            i +=1\n",
    "            \n",
    "print(\"vocab size:\",i)\n",
    "print(\"total occurrences of the special token ‘< unk >’:\",unkcount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4dbf1aa",
   "metadata": {
    "id": "d4dbf1aa"
   },
   "outputs": [],
   "source": [
    "pos = df.tag.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cdab233",
   "metadata": {
    "id": "9cdab233"
   },
   "outputs": [],
   "source": [
    "\n",
    "transition = {}\n",
    "deno = {}\n",
    "num_transition = {}\n",
    "\n",
    "for postag in pos:\n",
    "    deno[postag] = df['tag'].value_counts()[postag]\n",
    "\n",
    "for i in range(0, len(df)-1):\n",
    "    if (df.tag[i],df.tag[i+1]) in num_transition:\n",
    "        num_transition[(df.tag[i],df.tag[i+1])] += 1\n",
    "    else:\n",
    "        num_transition[(df.tag[i],df.tag[i+1])] = 1\n",
    "\n",
    "for pair in num_transition:\n",
    "    transition[pair[0],pair[1]] = num_transition[pair]/deno[pair[0]]\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744c9092",
   "metadata": {
    "id": "744c9092"
   },
   "outputs": [],
   "source": [
    "\n",
    "emission = {}\n",
    "num_emission = {}\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    if (df.tag[i],df.word[i]) in num_emission:\n",
    "        num_emission[(df.tag[i],df.word[i])] += 1\n",
    "    else:\n",
    "        num_emission[(df.tag[i],df.word[i])] = 1\n",
    "\n",
    "for pair1 in num_emission:\n",
    "    emission[pair1[0],pair1[1]] = num_emission[pair1]/deno[pair1[0]]\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c2a1eb",
   "metadata": {
    "id": "80c2a1eb"
   },
   "outputs": [],
   "source": [
    "\n",
    "transition_json = {str(key): value for key, value in transition.items()}\n",
    "emission_json = {str(key): value for key, value in emission.items()}\n",
    "\n",
    "\n",
    "\n",
    "data = {\"transition\": transition_json, \"emission\": emission_json}\n",
    "\n",
    "with open(\"hmm.json\", \"w\") as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a05e01a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a05e01a",
    "outputId": "aba8ca8c-b187-43cd-bf69-77f7a16d8584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transition parameters: 2025\n",
      "number of emission parameters: 618795\n"
     ]
    }
   ],
   "source": [
    "##transition mat\n",
    "\n",
    "transitionmat = [[0 for j in range(len(pos))] for i in range(len(pos))]\n",
    "\n",
    "\n",
    "poslist = pos.tolist()\n",
    "\n",
    "for (i, j), value in transition.items():\n",
    "    transitionmat[poslist.index(i)][poslist.index(j)] = value\n",
    "    \n",
    "print(\"number of transition parameters:\", len(transitionmat[0])*len(transitionmat))\n",
    "\n",
    "    \n",
    "## emission mat\n",
    "    \n",
    "words = df.word.unique()\n",
    "wordlist = words.tolist()\n",
    "\n",
    "emissionmat = [[0 for j in range(len(words))] for i in range(len(pos))]\n",
    "\n",
    "for (i, j), value in emission.items():\n",
    "    emissionmat[poslist.index(i)][wordlist.index(j)] = value\n",
    "    \n",
    "print(\"number of emission parameters:\", len(emissionmat[0])*len(emissionmat))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3195509f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3195509f",
    "outputId": "02c83c5d-3522-494c-8693-2cc029206c0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi\\AppData\\Local\\Temp\\ipykernel_14308\\3311191576.py:4: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dfdev.set_axis([\"index\", \"word\", \"tag\"], axis=\"columns\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for greedy on dev is 92.69549511262218\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dfdev = pd.read_table('data/dev', header=None)#,sep='\\t',lineterminator='\\n')\n",
    "dfdev.set_axis([\"index\", \"word\", \"tag\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "\n",
    "### Greedy decoding HMM ###\n",
    "\n",
    "initial = {}\n",
    "\n",
    "for postag in pos:\n",
    "    initial[postag] = deno[postag] / len(df)\n",
    "\n",
    "tag_predicted = {}\n",
    "\n",
    "for i in range(0, len(dfdev)): # for each word\n",
    "    if(dfdev.word[i] in wordlist):\n",
    "        curword = dfdev.word[i]\n",
    "    else:\n",
    "        curword = '<unk>'\n",
    "    curidx = wordlist.index(curword)\n",
    "    #print(curword)\n",
    "    indexlist =[]\n",
    "    for j in range(0, len(pos)): # for each tag\n",
    "        \n",
    "        if(dfdev['index'][i] != 1):\n",
    "            indexlist.append(transitionmat[poslist.index(tag_predicted[i-1])][j] * emissionmat[j][curidx])\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            indexlist.append(initial[pos[j]] * emissionmat[j][curidx])\n",
    "    tag_predicted[i] = pos[np.argmax(indexlist)]\n",
    "    \n",
    "            \n",
    "accuracycnt = 0\n",
    "for i in range(0, len(dfdev)):\n",
    "    if(dfdev.tag[i] == tag_predicted[i]):\n",
    "        accuracycnt += 1\n",
    "        \n",
    "accuracy = accuracycnt/len(dfdev)\n",
    "print(\"Accuracy for greedy on dev is\",accuracy*100)  \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c4a3ae",
   "metadata": {
    "id": "92c4a3ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi\\AppData\\Local\\Temp\\ipykernel_14308\\436268673.py:4: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dftest.set_axis([\"index\", \"word\"], axis=\"columns\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## runnning greedy on test data\n",
    "\n",
    "dftest = pd.read_table('data/test', header=None)#,sep='\\t',lineterminator='\\n')\n",
    "dftest.set_axis([\"index\", \"word\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "\n",
    "### Greedy decoding HMM ###\n",
    "\n",
    "\n",
    "tag_predicted = {}\n",
    "\n",
    "for i in range(0, len(dftest)): # for each word\n",
    "    if(dftest.word[i] in wordlist):\n",
    "        curword = dftest.word[i]\n",
    "    else:\n",
    "        curword = '<unk>'\n",
    "    curidx = wordlist.index(curword)\n",
    "    #print(curword)\n",
    "    indexlist =[]\n",
    "    for j in range(0, len(pos)): # for each tag\n",
    "        \n",
    "        if(dftest['index'][i] != 1):\n",
    "            indexlist.append(transitionmat[poslist.index(tag_predicted[i-1])][j] * emissionmat[j][curidx])\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            indexlist.append(initial[pos[j]] * emissionmat[j][curidx])\n",
    "    tag_predicted[i] = pos[np.argmax(indexlist)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b4d21b",
   "metadata": {
    "id": "09b4d21b"
   },
   "outputs": [],
   "source": [
    "## print value of greedy hmm decoding\n",
    "i = 0\n",
    "j = 1\n",
    "with open(\"greedy.out\", 'w') as f:\n",
    "    for i in range(0, len(dftest)):\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(dftest['index'][i]==1 and i!=0):\n",
    "            f.write('\\n')\n",
    "            j=1\n",
    "            f.write(str(j) + '\\t' + dftest.word[i] + '\\t' + str(tag_predicted[i]) + '\\n')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if(i!=0):\n",
    "                j+=1\n",
    "            f.write(str(j) + '\\t' + dftest.word[i] + '\\t' + str(tag_predicted[i]) + '\\n')\n",
    "            \n",
    "        i +=1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256606f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "256606f9",
    "outputId": "78a497cd-76b8-4b6c-eb06-9cca8d9d1ad4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi\\AppData\\Local\\Temp\\ipykernel_14308\\3315475516.py:5: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dfdev.set_axis([\"index\", \"word\", \"tag\"], axis=\"columns\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## self Viterbi HMM ##\n",
    "\n",
    "\n",
    "dfdev = pd.read_table('data/dev', header=None)#,sep='\\t',lineterminator='\\n')\n",
    "dfdev.set_axis([\"index\", \"word\", \"tag\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "prev_statelist = [] #memoizing the states\n",
    "history = [0] * len(pos)\n",
    "viterbi_final_taglist = []\n",
    "\n",
    "#for i in range(0, len(dfdev)): #every word\n",
    "for i in range(0, len(dfdev)):\n",
    "    if dfdev.word[i] in wordlist:\n",
    "        curword = dfdev.word[i]\n",
    "        #print(curword)\n",
    "    else:\n",
    "        curword = '<unk>' \n",
    "\n",
    "    curidx=wordlist.index(curword) \n",
    "\n",
    "    #print(curidx)\n",
    "    \n",
    "    if(curword != '.'): #not end of sentence\n",
    "    \n",
    "        if(dfdev['index'][i] == 1):#first word of sentence\n",
    "            #initial *  emission\n",
    "            prev_prob = [0] * len(pos)\n",
    "            prevstates = []\n",
    "\n",
    "            for j in range(0, len(pos)): #was pos\n",
    "                prev_prob[j]=initial[pos[j]] * emissionmat[j][curidx]\n",
    "            prevstates = [-1] *len(pos) #wasnone\n",
    "            prev_statelist.append(prevstates)\n",
    "            history = prev_prob\n",
    "            #print(prevstates)\n",
    "\n",
    "        else: # subsequent word in sentence \n",
    "            # trans * emission * previous\n",
    "\n",
    "            prev_prob = [0] * len(pos)\n",
    "            prevstates = [-1] * len(pos) #was0\n",
    "\n",
    "            for j in range(0, len(pos)): #was pos\n",
    "                curr_max_prob = 0\n",
    "                curr_state = -1\n",
    "\n",
    "                for k in range(0,len(pos)): #was pos\n",
    "\n",
    "                    prob = history[k] * transitionmat[k][j] * emissionmat[j][curidx]\n",
    "                    #print(curword)\n",
    "                    #print(curword,history[k],transitionmat[k][j],emissionmat[j][wordlist.index(curword)])\n",
    "                    if prob > curr_max_prob:\n",
    "                        curr_max_prob = prob\n",
    "                        curr_state = k\n",
    "                        #print(prob,k)\n",
    "                prev_prob[j] = curr_max_prob\n",
    "                prevstates[j] = curr_state\n",
    "\n",
    "            history = prev_prob\n",
    "            #print(prevstates)\n",
    "            prev_statelist.append(prevstates)\n",
    "        \n",
    "    else: #end of sentence\n",
    "        \n",
    "#         prevstates[-1]* len(pos)\n",
    "#         prevstates[10] = 1\n",
    "#         prev_statelist.append(prevstates)\n",
    "        \n",
    "             \n",
    "              \n",
    "        viterbi_taglist = []\n",
    "        viterbi_taglist.append(\".\")\n",
    "        \n",
    "        \n",
    "        prev_idx = np.argmax(history)\n",
    "        prev_tag = pos[prev_idx]\n",
    "        viterbi_taglist.append(prev_tag)\n",
    "        \n",
    "#         l=len(prev_statelist)-2\n",
    "        \n",
    "#         while(prev_tag != None):\n",
    "#             prev_idx = prev_statelist[l][prev_idx]\n",
    "#             prev_tag = str(poslist[prev_idx])\n",
    "#             viterbi_taglist.append(prev_tag)\n",
    "#             l -=1\n",
    "        for i in range(1,len(prev_statelist)):\n",
    "            #print(i)\n",
    "            prev_idx = prev_statelist[len(prev_statelist)-i][prev_idx]\n",
    "            prev_tag = str(poslist[prev_idx])\n",
    "            viterbi_taglist.append(prev_tag)\n",
    "\n",
    "        #print(prev_statelist)\n",
    "        viterbi_taglist.reverse()\n",
    "        viterbi_final_taglist.append(viterbi_taglist)\n",
    "            \n",
    "        \n",
    "        prev_statelist = [] #memoizing the states\n",
    "        history = [0] * len(pos)\n",
    "        \n",
    "        #argax of history\n",
    "        #assign index (argmax) = curr tag\n",
    "        #pos[value of argmax] = prev tag\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79b1f485",
   "metadata": {
    "id": "79b1f485"
   },
   "outputs": [],
   "source": [
    "viterbi_ans = []\n",
    "for i in range(len(viterbi_final_taglist)):\n",
    "    for j in range(len(viterbi_final_taglist[i])):\n",
    "        viterbi_ans.append(viterbi_final_taglist[i][j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12a0189a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12a0189a",
    "outputId": "d7ec1d9c-e9a9-4c2c-d819-8761df49e15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for viterbi on dev is 91.87435492684112\n"
     ]
    }
   ],
   "source": [
    "accuracycnt = 0\n",
    "for i in range(0, len(dfdev)):\n",
    "    if(dfdev.tag[i] == viterbi_ans[i]):\n",
    "        accuracycnt += 1\n",
    "        \n",
    "accuracy = accuracycnt/len(dfdev)\n",
    "print(\"Accuracy for viterbi on dev is\",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "952e92eb",
   "metadata": {
    "id": "952e92eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi\\AppData\\Local\\Temp\\ipykernel_14308\\3886722143.py:4: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dftest.set_axis([\"index\", \"word\"], axis=\"columns\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## runnning viterbi on test data\n",
    "\n",
    "dftest = pd.read_table('data/test', header=None)#,sep='\\t',lineterminator='\\n')\n",
    "dftest.set_axis([\"index\", \"word\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "prev_statelist = [] #memoizing the states\n",
    "history = [0] * len(pos)\n",
    "viterbi_final_taglist = []\n",
    "\n",
    "#for i in range(0, len(dftest)): #every word\n",
    "for i in range(0, len(dftest)):\n",
    "    if dftest.word[i] in wordlist:\n",
    "        curword = dftest.word[i]\n",
    "        #print(curword)\n",
    "    else:\n",
    "        curword = '<unk>' \n",
    "\n",
    "    curidx=wordlist.index(curword) \n",
    "\n",
    "    #print(curidx)\n",
    "    \n",
    "    if(curword != '.'): #not end of sentence\n",
    "    \n",
    "        if(dfdev['index'][i] == 1):#first word of sentence\n",
    "            #initial *  emission\n",
    "            prev_prob = [0] * len(pos)\n",
    "            prevstates = []\n",
    "\n",
    "            for j in range(0, len(pos)): #was pos\n",
    "                prev_prob[j]=initial[pos[j]] * emissionmat[j][curidx]\n",
    "            prevstates = [-1] *len(pos) #wasnone\n",
    "            prev_statelist.append(prevstates)\n",
    "            history = prev_prob\n",
    "            #print(prevstates)\n",
    "\n",
    "        else: # subsequent word in sentence \n",
    "            # trans * emission * previous\n",
    "\n",
    "            prev_prob = [0] * len(pos)\n",
    "            prevstates = [-1] * len(pos) #was0\n",
    "\n",
    "            for j in range(0, len(pos)): #was pos\n",
    "                curr_max_prob = 0\n",
    "                curr_state = -1\n",
    "\n",
    "                for k in range(0,len(pos)): #was pos\n",
    "\n",
    "                    prob = history[k] * transitionmat[k][j] * emissionmat[j][curidx]\n",
    "                    #print(curword)\n",
    "                    #print(curword,history[k],transitionmat[k][j],emissionmat[j][wordlist.index(curword)])\n",
    "                    if prob > curr_max_prob:\n",
    "                        curr_max_prob = prob\n",
    "                        curr_state = k\n",
    "                        #print(prob,k)\n",
    "                prev_prob[j] = curr_max_prob\n",
    "                prevstates[j] = curr_state\n",
    "\n",
    "            history = prev_prob\n",
    "            #print(prevstates)\n",
    "            prev_statelist.append(prevstates)\n",
    "        \n",
    "    else: #end of sentence\n",
    "        \n",
    "#         prevstates[-1]* len(pos)\n",
    "#         prevstates[10] = 1\n",
    "#         prev_statelist.append(prevstates)\n",
    "        \n",
    "             \n",
    "              \n",
    "        viterbi_taglist = []\n",
    "        viterbi_taglist.append(\".\")\n",
    "        \n",
    "        \n",
    "        prev_idx = np.argmax(history)\n",
    "        prev_tag = pos[prev_idx]\n",
    "        viterbi_taglist.append(prev_tag)\n",
    "        \n",
    "#         l=len(prev_statelist)-2\n",
    "        \n",
    "#         while(prev_tag != None):\n",
    "#             prev_idx = prev_statelist[l][prev_idx]\n",
    "#             prev_tag = str(poslist[prev_idx])\n",
    "#             viterbi_taglist.append(prev_tag)\n",
    "#             l -=1\n",
    "        for i in range(1,len(prev_statelist)):\n",
    "            #print(i)\n",
    "            prev_idx = prev_statelist[len(prev_statelist)-i][prev_idx]\n",
    "            prev_tag = str(poslist[prev_idx])\n",
    "            viterbi_taglist.append(prev_tag)\n",
    "\n",
    "        #print(prev_statelist)\n",
    "        viterbi_taglist.reverse()\n",
    "        viterbi_final_taglist.append(viterbi_taglist)\n",
    "            \n",
    "        \n",
    "        prev_statelist = [] #memoizing the states\n",
    "        history = [0] * len(pos)\n",
    "        \n",
    "        #argax of history\n",
    "        #assign index (argmax) = curr tag\n",
    "        #pos[value of argmax] = prev tag\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bnczlEOcQFOR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnczlEOcQFOR",
    "outputId": "3fb2d085-95fd-4059-95da-d4255f0cfab3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4110d509",
   "metadata": {
    "id": "4110d509"
   },
   "outputs": [],
   "source": [
    "## print value of viterbi hmm decoding\n",
    "i = 0\n",
    "j=1\n",
    "with open(\"viterbi.out\", 'w') as f:\n",
    "    for i in range(0, len(dftest)):\n",
    "        \n",
    "      \n",
    "        \n",
    "        if(dftest['index'][i]==1 and i!=0):\n",
    "            f.write('\\n')\n",
    "            j=1\n",
    "            f.write(str(j) + '\\t' + dftest.word[i] + '\\t' + str(viterbi_ans[i]) + '\\n')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if(i!=0):\n",
    "                j+=1\n",
    "            f.write(str(j) + '\\t' + dftest.word[i] + '\\t' + str(viterbi_ans[i]) + '\\n')\n",
    "            \n",
    "        i +=1\n",
    "        \n",
    "\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fbbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
